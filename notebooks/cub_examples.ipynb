{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/advDeep/dd2412-project/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder found. In order to download it, delete the existing folder!\n",
      "Dataset folder found. In order to download it, delete the existing folder!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from ct.data.cub import CUB\n",
    "from ct.model.cub_model import CUB_CT\n",
    "import warnings\n",
    "import argparse\n",
    "import torch\n",
    "import datetime\n",
    "import pytorch_lightning as pl\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from ct.model.cub_backbone import VIT_Backbone\n",
    "class args:\n",
    "    batch_size = 5\n",
    "    epochs = 50\n",
    "    lr = 1e-4\n",
    "    dim = 1024\n",
    "    num_heads = 16\n",
    "    expl_coeff = 1\n",
    "    n_global_concepts = 0\n",
    "    n_spatial_concepts = 0\n",
    "    n_classes = 0\n",
    "dataset = CUB(args.batch_size)\n",
    "dataset.setup()\n",
    "args.n_global_concepts = dataset.n_global_attr\n",
    "args.n_spatial_concepts = dataset.n_spatial_attr\n",
    "args.n_classes = int(dataset.n_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './logs/cub/2022-12-15_012505-bs=16,d=1024,e=200,ec=1.0,l=0.0001,nh=16,s=none,we=20'\n",
    "model_path = os.path.join(model_path, 'checkpoint', 'epoch=119-step=40560.ckpt')\n",
    "model = CUB_CT.load_from_checkpoint(model_path, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spatial_idx2attr_id = {}\n",
    "for key, value in dataset.test.attr_id2local_id.items():\n",
    "    spatial_idx2attr_id[value] = key\n",
    "global_idx2attr_id = {}\n",
    "for key, value in dataset.test.attr_id2global_id.items():\n",
    "    global_idx2attr_id[value] = key\n",
    "attributes = pd.read_csv('../data/cub/CUB_200_2011/attributes/attributes.txt', sep=' ', names=['attr_id', 'defi'])\n",
    "attr_id2def = pd.Series(data=attributes.defi, index=attributes.attr_id).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "image_folder = '../data/cub/CUB_200_2011/images/'\n",
    "model = model.to(device)\n",
    "mu = [0.485, 0.456, 0.406]\n",
    "sigma = [0.229, 0.224, 0.225]\n",
    "display_corrects = True\n",
    "max_batches = 5\n",
    "for batch in dataset.test_dataloader():\n",
    "    for k in batch.keys():\n",
    "        if k == 'image_path': continue\n",
    "        batch[k] = batch[k].to(device)\n",
    "    batch['image'] = torch.autograd.Variable(batch['image'].data, requires_grad=True)\n",
    "    target_class, global_concepts, spatial_concepts, predictions, attn_global, attn_spatial = model.predict_step(batch, None)\n",
    "    for i in range(args.batch_size):\n",
    "        if (predictions[i]==batch['label'][i]) ^ display_corrects:\n",
    "            continue\n",
    "        print(predictions[i], batch['label'][i])\n",
    "        image = batch['image'][i].cpu().detach().numpy()\n",
    "        image = np.moveaxis(image, 0, -1)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        global_attn = attn_global[i][0].cpu().detach().numpy()\n",
    "        spatial_attn = attn_spatial[i].cpu().detach().numpy()   \n",
    "        print(batch['image_path'][0][i])\n",
    "        for idx, a in enumerate(global_attn):\n",
    "            if a > 0:\n",
    "                print(attr_id2def[global_idx2attr_id[idx]])\n",
    "        for a in spatial_attn:\n",
    "            if a.max() > 0:\n",
    "                print(attr_id2def[spatial_idx2attr_id[np.argmax(a)]])\n",
    "        image[0] = image[0]*sigma[0] + mu[0]\n",
    "        image[1] = image[1]*sigma[1] + mu[1]\n",
    "        image[2] = image[2]*sigma[2] + mu[2]\n",
    "        break\n",
    "    max_batches -= 1\n",
    "    if max_batches <= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f15a3cb1f59790b8a195b11c10bab38b9e7d89f355ff7b85a4e8f1faf9cc3c7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
